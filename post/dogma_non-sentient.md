# Dogma for the non-sentient

> What I'm about to say may be BS

Imagine a child that has been indoctrinated to believe that:
- water doesn't move
- you can resurrect if you die
- real spiders are always 2meters wide
- \[insert ridiculous mythology]

Imagine another kid whose entire life consists of "shut up and calculate". If they take too long to answer, they get hit multiple times.

Imagine another kid, who hasn't even seen the light of the Sun. Their childhood consists of looking at weird images of blobs of lines, then categorizing them in buckets.

The reality might disturb you, but this is **happening right now all around the world**, and these kids are formally known as "computers".

I'm not saying this is bad, just that [dogmas are _bad for sentient beings_](https://youtu.be/0nz0iaNvVpE)(link title: "The ONE RULE for LIFE - Immanuel Kant's Moral Philosophy - Mark Manson") as it takes away their intellectual freedom (freedom of thought).

## Equivalence
A | B
--- | ---
coding | writing dogmas
software development | dogma design
creating axioms | claiming absolute truth
specifying protocols | mandating rituals

The analogy breaks down when one considers the diff between axioms and dogmas:
- Axioms are isolated to a conceptual space known as an Axiom System. The system must be consistent (no contradictions), otherwise information won't be preserved during data processing, since invariants and preconditions will be broken at any time.
- Dogmas are stated on top of existing reality (not isolated), disguising misinformation as true knowledge. These are totally careless about contradictions between themselves and/or reality, because they usually "evolve" naturally rather than being well-thought-out.

## Why
Why am I writing this? Because dogmas are always bad for humans, there's no excuse. But I want to propose that there are special cases where "dogma-like" stuff is useful, and that's computation and robotics.

Anything that can be considered sentient (such as animalia (including humans), aliens, and [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence)) should never be snatched of their intellectual freedom.

We should note that it's possible for AI to have _consciousness/self- awareness without being sentient_. This is an interesting gray-area that poses ethical/moral concerns
